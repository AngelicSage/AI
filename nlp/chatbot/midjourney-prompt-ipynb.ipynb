{"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8116627,"sourceType":"datasetVersion","datasetId":4795480}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -Uqqq pip\n!pip install -qqq torch==2.0.1\n!pip install -qqq -U git+https://github.com/huggingface/transformers.git@e03a9cc\n!pip install -qqq -U git+https://github.com/huggingface/peft.git@42a184f\n!pip install -qqq -U git+https://github.com/huggingface/accelerate.git@c9fbb71\n!pip install -qqq loralib==0.1.1\n!pip install -qqq einops==0.6.1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkLQo3pmo-Jk","outputId":"b3cfd82d-11b7-4d09-89a0-5ada013d0964","execution":{"iopub.status.busy":"2024-04-14T12:58:59.956628Z","iopub.execute_input":"2024-04-14T12:58:59.956993Z","iopub.status.idle":"2024-04-14T13:04:21.789865Z","shell.execute_reply.started":"2024-04-14T12:58:59.956963Z","shell.execute_reply":"2024-04-14T13:04:21.788400Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.30.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!nvcc --versions","metadata":{"id":"OKP8r5ni0FAr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d9c500f-58fe-4a7c-fbd1-6ffad6b48421","execution":{"iopub.status.busy":"2024-04-14T13:04:21.792124Z","iopub.execute_input":"2024-04-14T13:04:21.792473Z","iopub.status.idle":"2024-04-14T13:04:22.822454Z","shell.execute_reply.started":"2024-04-14T13:04:21.792443Z","shell.execute_reply":"2024-04-14T13:04:22.821204Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"nvcc fatal   : Unknown option '--versions'\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip uninstall bitsandbytes -y\n\n!pip install bitsandbytes","metadata":{"id":"oiwR7RK1rLFu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b1d619e-949f-45e7-fa9f-a804d1dae341","execution":{"iopub.status.busy":"2024-04-14T13:04:22.824048Z","iopub.execute_input":"2024-04-14T13:04:22.824447Z","iopub.status.idle":"2024-04-14T13:04:42.194733Z","shell.execute_reply.started":"2024-04-14T13:04:22.824409Z","shell.execute_reply":"2024-04-14T13:04:42.193403Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.0.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->bitsandbytes) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->bitsandbytes) (0.42.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch->bitsandbytes) (3.29.2)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch->bitsandbytes) (18.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets --quiet\n!pip install peft --quiet","metadata":{"id":"gdoD5Lw3rlfA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"71e0427b-218d-4a60-ad09-4b2f313d2763","execution":{"iopub.status.busy":"2024-04-14T13:04:42.197825Z","iopub.execute_input":"2024-04-14T13:04:42.198216Z","iopub.status.idle":"2024-04-14T13:05:08.535591Z","shell.execute_reply.started":"2024-04-14T13:04:42.198183Z","shell.execute_reply":"2024-04-14T13:05:08.534131Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import json\nimport os\nfrom pprint import pprint\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import load_dataset\nfrom huggingface_hub import notebook_login\nfrom peft import (\n    LoraConfig,\n    PeftConfig,\n    PeftModel,\n    get_peft_model,\n    prepare_model_for_kbit_training\n)\nfrom transformers import (\n    AutoConfig,\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig\n)\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"id":"YNvT2Uynpit-","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"92e2a5e0-b3d9-49a0-a52e-14be928987ba","execution":{"iopub.status.busy":"2024-04-14T13:05:08.537357Z","iopub.execute_input":"2024-04-14T13:05:08.537740Z","iopub.status.idle":"2024-04-14T13:05:25.815924Z","shell.execute_reply.started":"2024-04-14T13:05:08.537705Z","shell.execute_reply":"2024-04-14T13:05:25.814940Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-04-14 13:05:16.638293: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-14 13:05:16.638412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-14 13:05:16.747107: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"notebook_login()","metadata":{"id":"5bdd0Xi0ppev","execution":{"iopub.status.busy":"2024-04-14T13:43:04.208946Z","iopub.execute_input":"2024-04-14T13:43:04.209369Z","iopub.status.idle":"2024-04-14T13:43:04.236457Z","shell.execute_reply.started":"2024-04-14T13:43:04.209339Z","shell.execute_reply":"2024-04-14T13:43:04.235628Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76709569b6e34770a8adcaf8109d048e"}},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{"id":"fSP9JMCWsDJP"}},{"cell_type":"markdown","source":"# LOAD FALCON MODEL & TOKENIZER","metadata":{"id":"2bh3J5Ndp1lO"}},{"cell_type":"code","source":"MODEL_NAME = \"vilsonrodrigues/falcon-7b-instruct-sharded\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    quantization_config=bnb_config\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"id":"1GUD7mBRp2qH","execution":{"iopub.status.busy":"2024-04-14T13:08:19.911000Z","iopub.execute_input":"2024-04-14T13:08:19.911760Z","iopub.status.idle":"2024-04-14T13:16:53.703547Z","shell.execute_reply.started":"2024-04-14T13:08:19.911729Z","shell.execute_reply":"2024-04-14T13:16:53.702678Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"870c9c1541d64988a785dd861ff8a129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_falcon.py:   0%|          | 0.00/6.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dade745a312a40e3878dc7bbecf7d8d5"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/vilsonrodrigues/falcon-7b-instruct-sharded:\n- configuration_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be6881c8e02d438c9d51f3adcf7ba15f"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/vilsonrodrigues/falcon-7b-instruct-sharded:\n- modeling_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d736f0bcc1be4223a0cc270f768dccf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"618490709a07478e88d26c721e9fa00d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00015.safetensors:   0%|          | 0.00/1.68G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9adc6960d82f44aba02b3d9363588dbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fcd48b06bba4472995bd6352d2f24d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5404f0705d314012971b011d32776330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d73f769aa0454b3eb9e19ac0ae77c6a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a60a70d7972a47409d2b01fdbc61b45a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d34666e17e944ea780af56b219cf6d20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef258be6f8b740a5830ceba2a59bb56c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7889507fde7b4e2dac10f792a0d67b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00009-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc93d6a3cf8848ed96e6e742ccdef746"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00010-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87651a3ab0af46b587844131f033aafa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00011-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d906a03ed045d480fc81256d88967d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00012-of-00015.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb1bb21c2fa49dba2756bb369dade17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00013-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f97128b19e9469abb28769b16dbcff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00014-of-00015.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8659c6f723a94878b314a39f405d925f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00015-of-00015.safetensors:   0%|          | 0.00/828M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9a55ef2e8a2403f99c5cd8b7b4df16e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da99218315ac4cf9a4290dc47da47a7d"}},"metadata":{}},{"name":"stderr","text":"Some weights of FalconForCausalLM were not initialized from the model checkpoint at vilsonrodrigues/falcon-7b-instruct-sharded and are newly initialized: ['lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e343081da1124396aacddc42971d5b13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32a70033d1a458c8100e2269de724dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae49ebabdeb74f0ba759363b5d2374b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c83c6d5ebc674a01b48f3e6e6a178912"}},"metadata":{}}]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n  \"\"\"\n  Prints the number of trainable parameters in the model.\n  \"\"\"\n  trainable_params = 0\n  all_param = 0\n  for _, param in model.named_parameters():\n    all_param += param.numel()\n    if param.requires_grad:\n      trainable_params += param.numel()\n  print(\n      f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n  )","metadata":{"id":"RsxPa1WmmktC","execution":{"iopub.status.busy":"2024-04-14T13:16:53.705307Z","iopub.execute_input":"2024-04-14T13:16:53.705587Z","iopub.status.idle":"2024-04-14T13:16:53.712510Z","shell.execute_reply.started":"2024-04-14T13:16:53.705562Z","shell.execute_reply":"2024-04-14T13:16:53.711434Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"id":"VsvSHI6lml1S","execution":{"iopub.status.busy":"2024-04-14T13:16:53.713737Z","iopub.execute_input":"2024-04-14T13:16:53.714126Z","iopub.status.idle":"2024-04-14T13:16:53.742630Z","shell.execute_reply.started":"2024-04-14T13:16:53.714102Z","shell.execute_reply":"2024-04-14T13:16:53.741735Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"query_key_value\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)\nprint_trainable_parameters(model)","metadata":{"id":"6IgfANNJmnGx","execution":{"iopub.status.busy":"2024-04-14T13:16:53.745220Z","iopub.execute_input":"2024-04-14T13:16:53.746034Z","iopub.status.idle":"2024-04-14T13:17:00.443475Z","shell.execute_reply.started":"2024-04-14T13:16:53.745995Z","shell.execute_reply":"2024-04-14T13:17:00.442466Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"trainable params: 4718592 || all params: 3613463424 || trainables%: 0.13058363808693696\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Test original model","metadata":{"id":"NvUWzHR9p8nz"}},{"cell_type":"code","source":"prompt = \"\"\"\n<human>: midjourney prompt for a girl sit on the mountain\n<assistant>:\n\"\"\".strip()","metadata":{"id":"VB1lR2Yep-Im","execution":{"iopub.status.busy":"2024-04-14T13:17:00.444835Z","iopub.execute_input":"2024-04-14T13:17:00.445182Z","iopub.status.idle":"2024-04-14T13:17:00.450537Z","shell.execute_reply.started":"2024-04-14T13:17:00.445151Z","shell.execute_reply":"2024-04-14T13:17:00.449358Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"generation_config = model.generation_config\ngeneration_config.max_new_tokens = 200\ngeneration_config.temperature = 0.7\ngeneration_config.top_p = 0.7\ngeneration_config.num_return_sequences = 1\ngeneration_config.pad_token_id = tokenizer.eos_token_id\ngeneration_config.eos_token_id = tokenizer.eos_token_id","metadata":{"id":"Yu4xood_p_eg","execution":{"iopub.status.busy":"2024-04-14T13:17:00.452005Z","iopub.execute_input":"2024-04-14T13:17:00.452392Z","iopub.status.idle":"2024-04-14T13:17:00.459933Z","shell.execute_reply.started":"2024-04-14T13:17:00.452359Z","shell.execute_reply":"2024-04-14T13:17:00.458719Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"%%time\ndevice = \"cuda:0\"\n\nencoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\nwith torch.inference_mode():\n  outputs = model.generate(\n      input_ids = encoding.input_ids,\n      attention_mask = encoding.attention_mask,\n      generation_config = generation_config\n  )\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"id":"3l8_DfXuqBLu","execution":{"iopub.status.busy":"2024-04-14T13:17:00.461218Z","iopub.execute_input":"2024-04-14T13:17:00.461539Z","iopub.status.idle":"2024-04-14T13:17:07.496651Z","shell.execute_reply.started":"2024-04-14T13:17:00.461514Z","shell.execute_reply":"2024-04-14T13:17:07.495712Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"<human>: midjourney prompt for a girl sit on the mountain\n<assistant>: What do you want to do on the mountain?\n<human>: I want to take a break and enjoy the view.\n<assistant>: Alright, take your time.\n<human>: \nCPU times: user 4.43 s, sys: 172 ms, total: 4.6 s\nWall time: 7.02 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prep dataset","metadata":{"id":"lnnzcwuKqGn0"}},{"cell_type":"code","source":"data = load_dataset(\"csv\", data_files=\"/kaggle/input/midjourney/midjourney training dataset - midjourney_prompt_dataset.csv\")","metadata":{"id":"XVpOQJnSqJYp","execution":{"iopub.status.busy":"2024-04-14T13:19:12.288423Z","iopub.execute_input":"2024-04-14T13:19:12.288925Z","iopub.status.idle":"2024-04-14T13:19:12.877384Z","shell.execute_reply.started":"2024-04-14T13:19:12.288892Z","shell.execute_reply":"2024-04-14T13:19:12.876377Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ad797e5d47f4dd08c076db8766ea84c"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"id":"JPBLGZDcqX6g","execution":{"iopub.status.busy":"2024-04-14T13:19:17.893180Z","iopub.execute_input":"2024-04-14T13:19:17.894007Z","iopub.status.idle":"2024-04-14T13:19:17.900111Z","shell.execute_reply.started":"2024-04-14T13:19:17.893975Z","shell.execute_reply":"2024-04-14T13:19:17.899137Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['User', 'Prompt'],\n        num_rows: 288\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data[\"train\"][0]","metadata":{"id":"GbjbejfPqbYz","execution":{"iopub.status.busy":"2024-04-14T13:19:18.555771Z","iopub.execute_input":"2024-04-14T13:19:18.556647Z","iopub.status.idle":"2024-04-14T13:19:18.568584Z","shell.execute_reply.started":"2024-04-14T13:19:18.556612Z","shell.execute_reply":"2024-04-14T13:19:18.567608Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'User': '\"midjourney prompt for a Viking warrior with a black iron amulet\"',\n 'Prompt': '\"Norse amulet made from black iron with a carbon fiber necklace, matte painting, Unreal Engine, --ar 16:9\"'}"},"metadata":{}}]},{"cell_type":"code","source":"def generate_prompt(data_point):\n  return f\"\"\"\n<human>: {data_point[\"User\"]}\n<assistant>: {data_point[\"Prompt\"]}\n\"\"\".strip()\n\ndef generate_and_tokenize_prompt(data_point):\n  full_prompt = generate_prompt(data_point)\n  tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n  return tokenized_full_prompt","metadata":{"id":"UcNlEuwnqh4m","execution":{"iopub.status.busy":"2024-04-14T13:19:19.184356Z","iopub.execute_input":"2024-04-14T13:19:19.185318Z","iopub.status.idle":"2024-04-14T13:19:19.190437Z","shell.execute_reply.started":"2024-04-14T13:19:19.185281Z","shell.execute_reply":"2024-04-14T13:19:19.189467Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)","metadata":{"id":"i4jK1V20qiac","execution":{"iopub.status.busy":"2024-04-14T13:19:20.020225Z","iopub.execute_input":"2024-04-14T13:19:20.020612Z","iopub.status.idle":"2024-04-14T13:19:20.338021Z","shell.execute_reply.started":"2024-04-14T13:19:20.020581Z","shell.execute_reply":"2024-04-14T13:19:20.336970Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/288 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"030dc16dea2a4bda88940f00e3ccd54b"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"id":"v4w31zK0qk7A","execution":{"iopub.status.busy":"2024-04-14T13:19:20.956367Z","iopub.execute_input":"2024-04-14T13:19:20.957089Z","iopub.status.idle":"2024-04-14T13:19:20.962759Z","shell.execute_reply.started":"2024-04-14T13:19:20.957058Z","shell.execute_reply":"2024-04-14T13:19:20.961803Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['User', 'Prompt', 'input_ids', 'attention_mask'],\n    num_rows: 288\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Finetune the model","metadata":{"id":"kf_Vy70HsKGQ"}},{"cell_type":"code","source":"training_args = transformers.TrainingArguments(\n      per_device_train_batch_size=1,\n      gradient_accumulation_steps=4,\n      num_train_epochs=1,\n      learning_rate=2e-4,\n      fp16=True,\n      save_total_limit=3,\n      logging_steps=1,\n      output_dir=\"experiments\",\n      optim=\"paged_adamw_8bit\",\n      lr_scheduler_type=\"cosine\",\n      warmup_ratio=0.05,\n)\n\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=data,\n    args=training_args,\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)\nmodel.config.use_cache = False\ntrainer.train()","metadata":{"id":"UTjSAkYUsQqg","execution":{"iopub.status.busy":"2024-04-14T13:19:22.095876Z","iopub.execute_input":"2024-04-14T13:19:22.096738Z","iopub.status.idle":"2024-04-14T13:39:01.841259Z","shell.execute_reply.started":"2024-04-14T13:19:22.096707Z","shell.execute_reply":"2024-04-14T13:39:01.840177Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240414_133134-sskel7oh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/exapic/huggingface/runs/sskel7oh/workspace' target=\"_blank\">bumbling-breeze-1</a></strong> to <a href='https://wandb.ai/exapic/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/exapic/huggingface' target=\"_blank\">https://wandb.ai/exapic/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/exapic/huggingface/runs/sskel7oh/workspace' target=\"_blank\">https://wandb.ai/exapic/huggingface/runs/sskel7oh/workspace</a>"},"metadata":{}},{"name":"stderr","text":"You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [72/72 07:03, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.453300</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.840700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.598000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.437000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.344100</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>4.626400</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>4.382700</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>4.557900</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>4.272200</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>4.815500</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>4.377300</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>4.211800</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>4.014700</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>4.276400</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>3.789000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>3.784200</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>3.627800</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>3.835200</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>3.726500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>3.487000</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2.906700</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>3.372900</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>3.279400</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>3.317300</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>3.161900</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>2.732300</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>2.857300</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>2.728600</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>2.736700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>3.191000</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>3.432600</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>3.183600</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>2.956600</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>2.758100</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>2.639400</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>2.694400</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>2.839200</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>2.802100</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>3.210000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.836300</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>2.466800</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>2.965900</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>2.591400</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>2.842400</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>2.682300</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>2.511500</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>2.882500</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>2.457200</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>2.639600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.751700</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>2.980800</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>2.456100</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>2.678200</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>2.325500</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>2.453300</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>2.523200</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>2.314500</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>2.562600</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.609800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.866600</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>3.128100</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>2.416500</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>2.565000</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>2.628300</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>2.426500</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>2.274800</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>2.705900</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>2.623700</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>2.709900</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>2.073000</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>2.485300</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>2.750500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=72, training_loss=3.1450496945116253, metrics={'train_runtime': 1178.4779, 'train_samples_per_second': 0.244, 'train_steps_per_second': 0.061, 'total_flos': 425393421932544.0, 'train_loss': 3.1450496945116253, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Save trained model","metadata":{"id":"S0JaaueJs3Tt"}},{"cell_type":"code","source":"model.save_pretrained(\"trained-model\")","metadata":{"id":"bFCETjids62_","execution":{"iopub.status.busy":"2024-04-14T13:39:01.843026Z","iopub.execute_input":"2024-04-14T13:39:01.843313Z","iopub.status.idle":"2024-04-14T13:39:01.925586Z","shell.execute_reply.started":"2024-04-14T13:39:01.843288Z","shell.execute_reply":"2024-04-14T13:39:01.924480Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"PEFT_MODEL = \"WhyBless/midjourney-falcon-7b\"\n\nmodel.push_to_hub(\n    PEFT_MODEL, use_auth_token=True\n)","metadata":{"id":"sl_IzzKdtFtG","execution":{"iopub.status.busy":"2024-04-14T13:43:13.329626Z","iopub.execute_input":"2024-04-14T13:43:13.330015Z","iopub.status.idle":"2024-04-14T13:43:24.544341Z","shell.execute_reply.started":"2024-04-14T13:43:13.329985Z","shell.execute_reply":"2024-04-14T13:43:24.543133Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:289: UserWarning: About to update multiple times the same file in the same commit: 'adapter_model.bin'. This can cause undesired inconsistencies in your repo.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:289: UserWarning: About to update multiple times the same file in the same commit: 'adapter_config.json'. This can cause undesired inconsistencies in your repo.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/18.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda7e08f35334dfe8e28a3637bf3c062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68359bd12ec84ed998ee759f78c8a66e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/18.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4b5ca6b2bbd4def8418bb877c231b78"}},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/WhyBless/midjourney-falcon-7b/commit/3f8b7bf40f3aee37044373e094affeceda1cbd0e', commit_message='Upload model', commit_description='', oid='3f8b7bf40f3aee37044373e094affeceda1cbd0e', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"config = PeftConfig.from_pretrained(PEFT_MODEL)\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\ntokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = PeftModel.from_pretrained(model, PEFT_MODEL)","metadata":{"id":"1mUR2fpbtI7-","execution":{"iopub.status.busy":"2024-04-14T13:43:24.546429Z","iopub.execute_input":"2024-04-14T13:43:24.546868Z","iopub.status.idle":"2024-04-14T13:46:01.095504Z","shell.execute_reply.started":"2024-04-14T13:43:24.546828Z","shell.execute_reply":"2024-04-14T13:46:01.094391Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa0fc0bb3d6e47538693fdf8b4611135"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a3265c5f96b454b8b1dfca7c1e6fd5c"}},"metadata":{}},{"name":"stderr","text":"Some weights of FalconForCausalLM were not initialized from the model checkpoint at vilsonrodrigues/falcon-7b-instruct-sharded and are newly initialized: ['lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/18.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8bab85747044a19fae06de345b06d2"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Run the finetuned model","metadata":{"id":"jIs2DDuetQzF"}},{"cell_type":"code","source":"generation_config = model.generation_config\ngeneration_config.max_new_tokens = 200\ngeneration_config.temperature = 0.7\ngeneration_config.top_p = 0.7\ngeneration_config.num_return_sequences = 1\ngeneration_config.pad_token_id = tokenizer.eos_token_id\ngeneration_config.eos_token_id = tokenizer.eos_token_id","metadata":{"id":"ArdOBIwgtRQx","execution":{"iopub.status.busy":"2024-04-14T13:46:01.097800Z","iopub.execute_input":"2024-04-14T13:46:01.098237Z","iopub.status.idle":"2024-04-14T13:46:01.105166Z","shell.execute_reply.started":"2024-04-14T13:46:01.098186Z","shell.execute_reply":"2024-04-14T13:46:01.104156Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"%%time\ndevice = \"cuda:0\"\n\nprompt = \"\"\"\n<human>: midjourney prompt for a boy running in the snow\n<assistant>:\n\"\"\".strip()\n\nencoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\nwith torch.inference_mode():\n  outputs = model.generate(\n      input_ids = encoding.input_ids,\n      attention_mask = encoding.attention_mask,\n      generation_config = generation_config\n  )\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"id":"WvzZUmTttSgR","execution":{"iopub.status.busy":"2024-04-14T13:46:01.106777Z","iopub.execute_input":"2024-04-14T13:46:01.107062Z","iopub.status.idle":"2024-04-14T13:46:19.161483Z","shell.execute_reply.started":"2024-04-14T13:46:01.107037Z","shell.execute_reply":"2024-04-14T13:46:19.160564Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"<human>: midjourney prompt for a boy running in the snow\n<assistant>: A young boy running in the snow, with a backpack, and a red scarf --ar 16:9 --no-repeat --background-color --color-key --color-invert --brightness 0.8 --contrast 0.8 --saturation 0.8 --sharpness 0.8 --blur 0.8 --noise 0.8 --brightness-contrast 0.8 --color-contrast 0.8 --color-brightness 0.8 --color-contrast 0.8 --color-brightness 0.8 --color-contrast 0.8 --color-brightness 0.8 --color-contrast 0.8 --color-brightness 0.8 --color-contrast 0.8 --color-brightness 0\nCPU times: user 18 s, sys: 1.95 ms, total: 18 s\nWall time: 18 s\n","output_type":"stream"}]}]}